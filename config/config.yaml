# training hyper-parameters
num_epochs : 300
batch_size : 64
dropout_keep_prob : 0.8
clip_value : 100
learning_rate : 0.05
lambda_penalty : 0.001
l2 : 0.0001
seq_length : 100
optimizer : adam
early_stop_step : 5000000

# embeddings hyper-parameters
threshold : 0
embedding_size : 300
embedding_normalize : 1

# layers hyper-parameters
hidden_size : 200
rnn_size : 50
attention_size : 100
self_attention_r : 30

# report hyper-parameters
eval_batch : 5000

# IO path
## embeddings
vocab_path : ./SNLI/clean data/vocab.txt
embedding_path : ./SNLI/clean data/embeddings.pkl

## dataset
trainset_path : ./SNLI/clean data/train.txt
devset_path : ./SNLI/clean data/dev.txt
testset_path : ./SNLI/clean data/test.txt

## reports
save_path : ./model/checkpoint
best_path : ./model/bestval
log_path : ./config/log/log
tfboard_path : ./tensorboard

## config
config_path : ./config/config.yaml